#!/usr/bin/env python3
"""
Script t·∫°o Report Nh·∫≠n x√©t Huy·∫øt √°p theo Tu·∫ßn/Th√°ng
√Åp d·ª•ng SRS BR-005/BR-006
H·ªó tr·ª£ t·∫•t c·∫£ lo·∫°i ng∆∞·ªùi d√πng: THA, HA th·∫•p, BP Load, Kh√¥ng ·ªïn ƒë·ªãnh
Version: 3.0 - Universal
"""

import os
import sys
import csv
from datetime import datetime, timedelta
from collections import defaultdict

# Default thresholds - s·∫Ω ƒë∆∞·ª£c override t·ª´ user_health_profiles
DEFAULT_SYS_LOWER = 120
DEFAULT_SYS_UPPER = 140
DEFAULT_DIA_LOWER = 70
DEFAULT_DIA_UPPER = 90

# Khung gi·ªù ME diff
MORNING_START = 4
MORNING_END = 10
EVENING_START = 20
EVENING_END = 24

# Khung gi·ªù t∆∞∆°ng quan s·ª± ki·ªán (theo SRS)
EVENT_WINDOWS = {
    'medication': (1, 8),
    'stress': (0, 0.75),
    'caffeine': (0.5, 2),
    'exercise': (0.5, 2),
    'salt': (12, 24),
    'alcohol': (12, 24)
}

EVENT_NAMES = {
    'medication': 'U·ªëng thu·ªëc',
    'stress': 'Stress',
    'caffeine': 'Caffeine',
    'exercise': 'V·∫≠n ƒë·ªông',
    'salt': 'ƒÇn m·∫∑n',
    'alcohol': 'R∆∞·ª£u/Bia'
}

# Mapping has_hypertension
HAS_HYPERTENSION_LABELS = {
    1: ("THA ƒë√£ ch·∫©n ƒëo√°n", "kiem_soat"),
    2: ("HA th·∫•p", "hypotension_load"),
    3: ("HA kh√¥ng ·ªïn ƒë·ªãnh", "arv"),
    4: ("HA b√¨nh th∆∞·ªùng", "bp_load"),
    5: ("Ch∆∞a ch·∫©n ƒëo√°n THA", "bp_load"),
    6: ("Kh√¥ng r√µ", "bp_load")
}

def parse_datetime(dt_str):
    return datetime.strptime(dt_str.strip(), '%Y-%m-%d %H:%M:%S')

def is_morning(hour):
    return MORNING_START <= hour < MORNING_END

def is_evening(hour):
    return EVENING_START <= hour < EVENING_END

def get_week_monday(dt):
    days_since_monday = dt.weekday()
    return (dt - timedelta(days=days_since_monday)).date()

def classify_kiem_soat(percent):
    if percent > 70:
        return "Ki·ªÉm so√°t t·ªëi ∆∞u", ">70%"
    elif percent >= 50:
        return "Ki·ªÉm so√°t t·ªët", "50-70%"
    elif percent >= 25:
        return "Ki·ªÉm so√°t k√©m", "25-50%"
    else:
        return "Kh√¥ng ki·ªÉm so√°t", "<25%"

def classify_bp_load(percent):
    """Ph√¢n lo·∫°i BP Load cho ng∆∞·ªùi ch∆∞a ch·∫©n ƒëo√°n THA"""
    if percent < 15:
        return "B√¨nh th∆∞·ªùng", "<15%", "H·ªá tim m·∫°ch ƒëang ƒë∆∞·ª£c b·∫£o v·ªá t·ªët."
    elif percent <= 30:
        return "Ch·ªõm cao", "15-30%", "B·∫Øt ƒë·∫ßu c√≥ d·∫•u hi·ªáu qu√° t·∫£i, c·∫ßn ƒëi·ªÅu ch·ªânh l·ªëi s·ªëng."
    else:
        return "G√°nh n·∫∑ng l·ªõn", ">30%", "Nguy c∆° cao g√¢y t·ªïn th∆∞∆°ng tim, th·∫≠n. C·∫ßn can thi·ªáp y t·∫ø."

def classify_hypotension_load(percent):
    """Ph√¢n lo·∫°i Hypotension Load cho ng∆∞·ªùi HA th·∫•p"""
    if percent < 15:
        return "√çt khi th·∫•p", "<15%", "Huy·∫øt √°p th·∫•p kh√¥ng th∆∞·ªùng xuy√™n."
    elif percent <= 30:
        return "Th∆∞·ªùng xuy√™n th·∫•p", "15-30%", "C∆° th·ªÉ thi·∫øu m√°u/oxy ·ªü m·ª©c ƒë·ªô v·ª´a."
    else:
        return "R·ªßi ro t·ª•t HA", ">30%", "Nguy c∆° cao t√© ng√£, cho√°ng do thi·∫øu m√°u n√£o."

def classify_arv(arv):
    if arv < 10:
        return "·ªîn ƒë·ªãnh", "<10"
    elif arv <= 14:
        return "Bi·∫øn ƒë·ªông", "10-14"
    else:
        return "B·∫•t ·ªïn", ">14"

def classify_mediff(mediff):
    if mediff > 15:
        return "V·ªçt √°p bu·ªïi s√°ng", ">15 mmHg"
    elif mediff < -15:
        return "TƒÉng √°p v·ªÅ t·ªëi", "<-15 mmHg"
    else:
        return "C√¢n b·∫±ng", "-15~15 mmHg"

def calculate_arv_with_time(week_data):
    if len(week_data) < 2:
        return 0
    sorted_data = sorted(week_data, key=lambda x: x['dt'])
    diffs = []
    for i in range(len(sorted_data) - 1):
        time_diff = (sorted_data[i+1]['dt'] - sorted_data[i]['dt']).total_seconds() / 3600
        if time_diff <= 24:
            diffs.append(abs(sorted_data[i+1]['sys'] - sorted_data[i]['sys']))
    if not diffs:
        return 0
    return sum(diffs) / len(diffs)

def get_bp_highest(data):
    if not data:
        return None, None
    sorted_data = sorted(data, key=lambda x: (-x['sys'], -x['dia']))
    return sorted_data[0]['sys'], sorted_data[0]['dia']

def get_bp_lowest(data):
    if not data:
        return None, None
    sorted_data = sorted(data, key=lambda x: (x['sys'], x['dia']))
    return sorted_data[0]['sys'], sorted_data[0]['dia']

def load_user_config(user_dir):
    """ƒê·ªçc th√¥ng tin user t·ª´ users.csv v√† user_health_profiles.csv"""
    config = {
        'user_name': 'Unknown',
        'has_hypertension': 1,
        'user_type': 'THA ƒë√£ ch·∫©n ƒëo√°n',
        'analysis_type': 'kiem_soat',
        'sys_lower': DEFAULT_SYS_LOWER,
        'sys_upper': DEFAULT_SYS_UPPER,
        'dia_lower': DEFAULT_DIA_LOWER,
        'dia_upper': DEFAULT_DIA_UPPER
    }
    
    # ƒê·ªçc users.csv
    users_file = os.path.join(user_dir, 'users.csv')
    if os.path.exists(users_file):
        with open(users_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                config['user_name'] = os.path.basename(user_dir)
                config['has_hypertension'] = int(row.get('has_hypertension', 1))
                break
    
    # ƒê·ªçc health_profiles
    profiles_file = os.path.join(user_dir, 'user_health_profiles.csv')
    if os.path.exists(profiles_file):
        with open(profiles_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('systolic_threshold_lower'):
                    config['sys_lower'] = int(row['systolic_threshold_lower'])
                if row.get('systolic_threshold_upper'):
                    config['sys_upper'] = int(row['systolic_threshold_upper'])
                if row.get('diastolic_threshold_lower'):
                    config['dia_lower'] = int(row['diastolic_threshold_lower'])
                if row.get('diastolic_threshold_upper'):
                    config['dia_upper'] = int(row['diastolic_threshold_upper'])
                break
    
    # Map lo·∫°i ng∆∞·ªùi d√πng
    ht = config['has_hypertension']
    if ht in HAS_HYPERTENSION_LABELS:
        config['user_type'], config['analysis_type'] = HAS_HYPERTENSION_LABELS[ht]
    
    return config

def load_events(user_dir):
    events = []
    events_file = os.path.join(user_dir, 'events.csv')
    if os.path.exists(events_file):
        with open(events_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('event_time'):
                    events.append({
                        'dt': parse_datetime(row['event_time']),
                        'type': row['event_type'],
                        'notes': row.get('notes', '')
                    })
    return events

def analyze_event_correlation(week_data, events, week_start, week_end):
    correlations = []
    week_events = [e for e in events 
                   if week_start - timedelta(days=1) <= e['dt'].date() <= week_end]
    
    for event in week_events:
        event_type = event['type']
        if event_type not in EVENT_WINDOWS:
            continue
        
        window_start_h, window_end_h = EVENT_WINDOWS[event_type]
        bp_after_event = []
        for bp in week_data:
            hours_diff = (bp['dt'] - event['dt']).total_seconds() / 3600
            if window_start_h <= hours_diff <= window_end_h:
                bp_after_event.append(bp)
        
        if bp_after_event:
            sys_avg = sum(b['sys'] for b in bp_after_event) / len(bp_after_event)
            correlations.append({
                'event': EVENT_NAMES.get(event_type, event_type),
                'time': event['dt'].strftime('%d/%m %H:%M'),
                'bp_count': len(bp_after_event),
                'sys_avg': sys_avg,
            })
    return correlations

def analyze_abnormal(data, config):
    is_in_target = lambda sys, dia: (config['sys_lower'] <= sys <= config['sys_upper']) and \
                                     (config['dia_lower'] <= dia <= config['dia_upper'])
    
    out_of_target = [r for r in data if not is_in_target(r['sys'], r['dia'])]
    count_out = len(out_of_target)
    
    morning_out = sum(1 for r in out_of_target if 4 <= r['dt'].hour < 12)
    afternoon_out = sum(1 for r in out_of_target if 12 <= r['dt'].hour < 18)
    evening_out = sum(1 for r in out_of_target if r['dt'].hour >= 18 or r['dt'].hour < 4)
    
    peak_time = "s√°ng" if morning_out >= max(afternoon_out, evening_out) else \
                "chi·ªÅu" if afternoon_out >= evening_out else "t·ªëi"
    
    if out_of_target:
        max_bp = max(out_of_target, key=lambda x: x['sys'])
        peak_day = max_bp['dt'].strftime('%d/%m')
        peak_value = f"{max_bp['sys']}/{max_bp['dia']}"
    else:
        peak_day = None
        peak_value = None
    
    return {
        'count_out': count_out,
        'total': len(data),
        'peak_time': peak_time,
        'morning_out': morning_out,
        'afternoon_out': afternoon_out,
        'evening_out': evening_out,
        'peak_day': peak_day,
        'peak_value': peak_value
    }

def analyze_hr(data, prev_data=None):
    hr_values = [r['hr'] for r in data]
    hr_avg = sum(hr_values) / len(hr_values)
    hr_max = max(hr_values)
    hr_min = min(hr_values)
    
    too_fast = sum(1 for hr in hr_values if hr > 100)
    too_slow = sum(1 for hr in hr_values if hr < 60)
    
    trend = None
    if prev_data:
        prev_hr = [r['hr'] for r in prev_data]
        prev_avg = sum(prev_hr) / len(prev_hr)
        diff = hr_avg - prev_avg
        if diff > 5:
            trend = f"TƒÉng +{diff:.0f} bpm so v·ªõi k·ª≥ tr∆∞·ªõc"
        elif diff < -5:
            trend = f"Gi·∫£m {diff:.0f} bpm so v·ªõi k·ª≥ tr∆∞·ªõc"
        else:
            trend = "·ªîn ƒë·ªãnh so v·ªõi k·ª≥ tr∆∞·ªõc"
    
    return {
        'avg': hr_avg,
        'max': hr_max,
        'min': hr_min,
        'too_fast': too_fast,
        'too_slow': too_slow,
        'trend': trend
    }

def generate_week_report(week_start, week_data, week_num, events, config, prev_week_data=None, prev_sys_avg=None):
    week_end = week_start + timedelta(days=6)
    
    is_in_target = lambda sys, dia: (config['sys_lower'] <= sys <= config['sys_upper']) and \
                                     (config['dia_lower'] <= dia <= config['dia_upper'])
    
    total = len(week_data)
    in_target = sum(1 for r in week_data if is_in_target(r['sys'], r['dia']))
    kiem_soat = (in_target / total * 100) if total > 0 else 0
    
    sys_values = [r['sys'] for r in week_data]
    dia_values = [r['dia'] for r in week_data]
    hr_values = [r['hr'] for r in week_data]
    
    sys_avg = sum(sys_values) / len(sys_values)
    dia_avg = sum(dia_values) / len(dia_values)
    hr_avg = sum(hr_values) / len(hr_values)
    
    arv = calculate_arv_with_time(week_data)
    bp_high_sys, bp_high_dia = get_bp_highest(week_data)
    bp_low_sys, bp_low_dia = get_bp_lowest(week_data)
    
    # ME diff
    morning_sys = [r['sys'] for r in week_data if is_morning(r['dt'].hour)]
    evening_sys = [r['sys'] for r in week_data if is_evening(r['dt'].hour)]
    
    if morning_sys and evening_sys:
        mediff = sum(morning_sys)/len(morning_sys) - sum(evening_sys)/len(evening_sys)
        mediff_class, mediff_note = classify_mediff(mediff)
    else:
        mediff = None
        mediff_class = "Kh√¥ng ƒë·ªß d·ªØ li·ªáu"
        mediff_note = "Thi·∫øu d·ªØ li·ªáu s√°ng/t·ªëi"
    
    arv_class, arv_note = classify_arv(arv)
    
    days_with_data = len(set(r['dt'].date() for r in week_data))
    compliance = days_with_data / 7 * 100
    
    correlations = analyze_event_correlation(week_data, events, week_start, week_end)
    abnormal = analyze_abnormal(week_data, config)
    hr_analysis = analyze_hr(week_data, prev_week_data)
    
    trend_text = ""
    if prev_sys_avg:
        diff_sys = sys_avg - prev_sys_avg
        if diff_sys > 5:
            trend_text = f"üìà TƒÉng +{diff_sys:.0f} mmHg so v·ªõi tu·∫ßn tr∆∞·ªõc"
        elif diff_sys < -5:
            trend_text = f"üìâ Gi·∫£m {diff_sys:.0f} mmHg so v·ªõi tu·∫ßn tr∆∞·ªõc"
        else:
            trend_text = f"‚û°Ô∏è ·ªîn ƒë·ªãnh so v·ªõi tu·∫ßn tr∆∞·ªõc ({diff_sys:+.0f} mmHg)"
    
    # T·∫°o markdown
    report = f"""# üìä B√°o C√°o Huy·∫øt √Åp Tu·∫ßn {week_num}

> **User:** {config['user_name']} ({config['user_type']})  
> **K·ª≥ b√°o c√°o:** {week_start.strftime('%d/%m/%Y')} - {week_end.strftime('%d/%m/%Y')}  
> **Ng∆∞·ª°ng m·ª•c ti√™u:** SYS {config['sys_lower']}-{config['sys_upper']}, DIA {config['dia_lower']}-{config['dia_upper']} mmHg

---

## 1. T·ªïng Quan Theo D√µi

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|:---|:---|
| S·ªë l·∫ßn ƒëo | {total} l·∫ßn |
| S·ªë ng√†y c√≥ ƒëo | {days_with_data}/7 ng√†y |
| T·ª∑ l·ªá tu√¢n th·ªß | {compliance:.1f}% |

{f"**{trend_text}**" if trend_text else ""}

---

## 2. Ph√¢n T√≠ch Huy·∫øt √Åp

### 2.1 T·ªïng quan ch·ªâ s·ªë

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|:---|:---|
| **HA Trung b√¨nh** | {sys_avg:.0f}/{dia_avg:.0f} mmHg |
| **HA Cao nh·∫•t** | {bp_high_sys}/{bp_high_dia} mmHg |
| **HA Th·∫•p nh·∫•t** | {bp_low_sys}/{bp_low_dia} mmHg |
| **Nh·ªãp tim TB** | {hr_avg:.0f} bpm |

"""
    
    # Nh·∫≠n x√©t ch√≠nh d·ª±a tr√™n lo·∫°i ng∆∞·ªùi d√πng
    analysis_type = config['analysis_type']
    
    if analysis_type == 'kiem_soat':
        kiem_soat_class, kiem_soat_note = classify_kiem_soat(kiem_soat)
        report += f"""### 2.2 M·ª©c ƒë·ªô Ki·ªÉm so√°t HA

| Ch·ªâ s·ªë | Gi√° tr·ªã | Ph√¢n lo·∫°i | Ng∆∞·ª°ng |
|:---|:---|:---|:---|
| **% trong ng∆∞·ª°ng** | {kiem_soat:.1f}% | **{kiem_soat_class}** | {kiem_soat_note} |

> **Di·ªÖn gi·∫£i:** """
        if kiem_soat > 70:
            report += "Huy·∫øt √°p r·∫•t ·ªïn ƒë·ªãnh, ƒë·∫°t tr·∫°ng th√°i l√Ω t∆∞·ªüng."
        elif kiem_soat >= 50:
            report += "ƒê·∫°t y√™u c·∫ßu ƒëi·ªÅu tr·ªã. ƒêa s·ªë th·ªùi gian c∆° th·ªÉ ƒë∆∞·ª£c b·∫£o v·ªá."
        elif kiem_soat >= 25:
            report += "Huy·∫øt √°p dao ƒë·ªông nhi·ªÅu. Hi·ªáu qu·∫£ thu·ªëc ch∆∞a ·ªïn ƒë·ªãnh."
        else:
            report += "Nguy c∆° bi·∫øn c·ªë cao. C·∫ßn can thi·ªáp y t·∫ø."
    
    elif analysis_type == 'bp_load':
        # T√≠nh BP Load (v∆∞·ª£t ng∆∞·ª°ng 140/90)
        bp_over = sum(1 for r in week_data if r['sys'] > 140 or r['dia'] > 90)
        bp_load_percent = (bp_over / total * 100) if total > 0 else 0
        bp_load_class, bp_load_note, bp_load_explain = classify_bp_load(bp_load_percent)
        report += f"""### 2.2 G√°nh n·∫∑ng Huy·∫øt √°p (BP Load)

| Ch·ªâ s·ªë | Gi√° tr·ªã | Ph√¢n lo·∫°i | Ng∆∞·ª°ng |
|:---|:---|:---|:---|
| **BP Load** | {bp_load_percent:.1f}% | **{bp_load_class}** | {bp_load_note} |

> **Di·ªÖn gi·∫£i:** {bp_load_explain}"""
    
    elif analysis_type == 'hypotension_load':
        # T√≠nh Hypotension Load (d∆∞·ªõi 90/60)
        hypo_count = sum(1 for r in week_data if r['sys'] < 90 or r['dia'] < 60)
        hypo_percent = (hypo_count / total * 100) if total > 0 else 0
        hypo_class, hypo_note, hypo_explain = classify_hypotension_load(hypo_percent)
        report += f"""### 2.2 T·∫ßn su·∫•t Huy·∫øt √°p th·∫•p (Hypotension Load)

| Ch·ªâ s·ªë | Gi√° tr·ªã | Ph√¢n lo·∫°i | Ng∆∞·ª°ng |
|:---|:---|:---|:---|
| **Hypotension Load** | {hypo_percent:.1f}% | **{hypo_class}** | {hypo_note} |

> **Di·ªÖn gi·∫£i:** {hypo_explain}"""
    
    else:  # arv - kh√¥ng ·ªïn ƒë·ªãnh
        report += f"""### 2.2 M·ª©c ƒë·ªô ·ªîn ƒë·ªãnh HA

| Ch·ªâ s·ªë | Gi√° tr·ªã | Ph√¢n lo·∫°i | Ng∆∞·ª°ng |
|:---|:---|:---|:---|
| **% trong ng∆∞·ª°ng** | {kiem_soat:.1f}% | - | - |

> **Nh·∫≠n x√©t:** Huy·∫øt √°p kh√¥ng ·ªïn ƒë·ªãnh, c·∫ßn theo d√µi ARV v√† ME diff."""
    
    report += f"""

### 2.3 ƒê·ªô ·ªîn ƒê·ªãnh HA (ARV)

| Ch·ªâ s·ªë | Gi√° tr·ªã | Ph√¢n lo·∫°i | Ng∆∞·ª°ng |
|:---|:---|:---|:---|
| **ARV t√¢m thu** | {arv:.1f} | **{arv_class}** | {arv_note} |

> **Di·ªÖn gi·∫£i:** """

    if arv < 10:
        report += "H·ªá m·∫°ch v·∫≠n h√†nh √™m √°i, √≠t √°p l·ª±c c∆° h·ªçc."
    elif arv <= 14:
        report += "M·∫°ch m√°u b·∫Øt ƒë·∫ßu ch·ªãu √°p l·ª±c t·ª´ dao ƒë·ªông."
    else:
        report += "Nguy c∆° cao t·ªïn th∆∞∆°ng th√†nh m·∫°ch."

    report += f"""

### 2.4 Nh·ªãp Sinh H·ªçc HA (ME diff)

| Ch·ªâ s·ªë | Gi√° tr·ªã | Ph√¢n lo·∫°i | Ng∆∞·ª°ng |
|:---|:---|:---|:---|
| **ME diff** | {f"{mediff:+.0f}" if mediff else "N/A"} mmHg | **{mediff_class}** | {mediff_note} |

> **Di·ªÖn gi·∫£i:** """

    if mediff is not None:
        if mediff > 15:
            report += "V·ªçt √°p bu·ªïi s√°ng - tƒÉng nguy c∆° ƒë·ªôt qu·ªµ s√°ng s·ªõm."
        elif mediff < -15:
            report += "Non-dipper - r·∫•t h·∫°i cho tim v√† th·∫≠n."
        else:
            report += "Nh·ªãp sinh h·ªçc ·ªïn ƒë·ªãnh."
    else:
        report += "Thi·∫øu d·ªØ li·ªáu s√°ng/t·ªëi."

    report += f"""

### 2.5 Ph√°t Hi·ªán B·∫•t Th∆∞·ªùng

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|:---|:---|
| **S·ªë l·∫ßn v∆∞·ª£t ng∆∞·ª°ng** | {abnormal['count_out']}/{abnormal['total']} l·∫ßn ({100-kiem_soat:.1f}%) |
| **Th·ªùi ƒëi·ªÉm th∆∞·ªùng x·∫£y ra** | Bu·ªïi {abnormal['peak_time']} |
| **Ph√¢n b·ªë** | S√°ng: {abnormal['morning_out']}, Chi·ªÅu: {abnormal['afternoon_out']}, T·ªëi: {abnormal['evening_out']} |"""

    if abnormal['peak_day']:
        report += f"""
| **Ng√†y HA cao nh·∫•t** | {abnormal['peak_day']} ({abnormal['peak_value']} mmHg) |"""

    if correlations:
        report += f"""

---

## 3. T∆∞∆°ng Quan V·ªõi S·ª± Ki·ªán

| S·ª± ki·ªán | Th·ªùi ƒëi·ªÉm | S·ªë l·∫ßn ƒëo sau | SYS TB sau |
|:---|:---|:---:|:---:|"""
        for c in correlations:
            report += f"""
| {c['event']} | {c['time']} | {c['bp_count']} | {c['sys_avg']:.0f} mmHg |"""
        report += """

> **Ghi ch√∫:** C√°c y·∫øu t·ªë nh∆∞ stress, caffeine, r∆∞·ª£u bia c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn huy·∫øt √°p."""

    report += f"""

---

## 4. Ph√¢n T√≠ch Nh·ªãp Tim

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|:---|:---|
| **Nh·ªãp tim Trung b√¨nh** | {hr_analysis['avg']:.0f} bpm |
| **Nh·ªãp tim Cao nh·∫•t** | {hr_analysis['max']} bpm |
| **Nh·ªãp tim Th·∫•p nh·∫•t** | {hr_analysis['min']} bpm |"""

    if hr_analysis['trend']:
        report += f"""
| **Xu h∆∞·ªõng** | {hr_analysis['trend']} |"""

    if hr_analysis['too_fast'] > 0 or hr_analysis['too_slow'] > 0:
        report += f"""

‚ö†Ô∏è **B·∫•t th∆∞·ªùng:** Nhanh (>100): {hr_analysis['too_fast']}, Ch·∫≠m (<60): {hr_analysis['too_slow']}"""
    else:
        report += """

‚úÖ **Nh·ªãp tim ·ªïn ƒë·ªãnh** trong ng∆∞·ª°ng 60-100 bpm."""

    report += f"""

---

## 5. Khuy·∫øn Ngh·ªã

"""
    if kiem_soat > 70 and arv < 10:
        report += """‚úÖ **T√¨nh tr·∫°ng t·ªët!** Ti·∫øp t·ª•c duy tr√¨ th√≥i quen hi·ªán t·∫°i."""
    elif kiem_soat >= 50:
        report += """‚ö†Ô∏è **C·∫ßn c·∫£i thi·ªán:** Ki·ªÉm tra vi·ªác tu√¢n th·ªß thu·ªëc, h·∫°n ch·∫ø mu·ªëi."""
    else:
        report += """üö® **C·∫ßn ch√∫ √Ω:** Li√™n h·ªá b√°c sƒ© ƒë·ªÉ ƒë√°nh gi√° l·∫°i ph√°c ƒë·ªì."""

    report += f"""

---

> *B√°o c√°o ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông theo SRS BR-005/BR-006*  
> *L∆∞u √Ω: B√°o c√°o n√†y kh√¥ng thay th·∫ø t∆∞ v·∫•n y khoa chuy√™n m√¥n.*
"""
    
    return report, sys_avg

def generate_month_report(month_key, month_data, config, prev_month_data=None):
    year, month = month_key
    
    is_in_target = lambda sys, dia: (config['sys_lower'] <= sys <= config['sys_upper']) and \
                                     (config['dia_lower'] <= dia <= config['dia_upper'])
    
    total = len(month_data)
    in_target = sum(1 for r in month_data if is_in_target(r['sys'], r['dia']))
    kiem_soat = (in_target / total * 100) if total > 0 else 0
    
    sys_values = [r['sys'] for r in month_data]
    dia_values = [r['dia'] for r in month_data]
    hr_values = [r['hr'] for r in month_data]
    
    sys_avg = sum(sys_values) / len(sys_values)
    dia_avg = sum(dia_values) / len(dia_values)
    hr_avg = sum(hr_values) / len(hr_values)
    
    days_with_data = len(set(r['dt'].date() for r in month_data))
    
    bp_high_sys, bp_high_dia = get_bp_highest(month_data)
    bp_low_sys, bp_low_dia = get_bp_lowest(month_data)
    arv = calculate_arv_with_time(month_data)
    arv_class, arv_note = classify_arv(arv)
    
    morning_sys = [r['sys'] for r in month_data if is_morning(r['dt'].hour)]
    evening_sys = [r['sys'] for r in month_data if is_evening(r['dt'].hour)]
    
    if morning_sys and evening_sys:
        mediff = sum(morning_sys)/len(morning_sys) - sum(evening_sys)/len(evening_sys)
        mediff_class, mediff_note = classify_mediff(mediff)
    else:
        mediff = None
        mediff_class = "Kh√¥ng ƒë·ªß d·ªØ li·ªáu"
        mediff_note = "Thi·∫øu d·ªØ li·ªáu"
    
    abnormal = analyze_abnormal(month_data, config)
    hr_analysis = analyze_hr(month_data, prev_month_data)
    
    trend = ""
    if prev_month_data:
        prev_in_target = sum(1 for r in prev_month_data if is_in_target(r['sys'], r['dia']))
        prev_kiem_soat = (prev_in_target / len(prev_month_data) * 100) if prev_month_data else 0
        diff = kiem_soat - prev_kiem_soat
        if diff > 5:
            trend = f"üìà C·∫£i thi·ªán +{diff:.1f}% so v·ªõi th√°ng tr∆∞·ªõc"
        elif diff < -5:
            trend = f"üìâ Gi·∫£m {diff:.1f}% so v·ªõi th√°ng tr∆∞·ªõc"
        else:
            trend = f"‚û°Ô∏è ·ªîn ƒë·ªãnh so v·ªõi th√°ng tr∆∞·ªõc"
    
    month_names = {1: "Th√°ng 1", 2: "Th√°ng 2", 3: "Th√°ng 3", 4: "Th√°ng 4", 
                   5: "Th√°ng 5", 6: "Th√°ng 6", 7: "Th√°ng 7", 8: "Th√°ng 8",
                   9: "Th√°ng 9", 10: "Th√°ng 10", 11: "Th√°ng 11", 12: "Th√°ng 12"}
    
    report = f"""# üìä B√°o C√°o Huy·∫øt √Åp {month_names[month]} {year}

> **User:** {config['user_name']} ({config['user_type']})  
> **K·ª≥ b√°o c√°o:** {month_names[month]} {year}  
> **Ng∆∞·ª°ng m·ª•c ti√™u:** SYS {config['sys_lower']}-{config['sys_upper']}, DIA {config['dia_lower']}-{config['dia_upper']} mmHg

---

## 1. T·ªïng Quan Theo D√µi

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|:---|:---|
| **T·ªïng s·ªë l·∫ßn ƒëo** | {total} l·∫ßn |
| **S·ªë ng√†y c√≥ ƒëo** | {days_with_data} ng√†y |
| **T·ª∑ l·ªá ƒëo trong ng∆∞·ª°ng** | {kiem_soat:.1f}% |

{f"**{trend}**" if trend else ""}

---

## 2. Ph√¢n T√≠ch Huy·∫øt √Åp

### 2.1 T·ªïng quan ch·ªâ s·ªë th√°ng

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|:---|:---|
| **HA Trung b√¨nh** | {sys_avg:.0f}/{dia_avg:.0f} mmHg |
| **HA Cao nh·∫•t** | {bp_high_sys}/{bp_high_dia} mmHg |
| **HA Th·∫•p nh·∫•t** | {bp_low_sys}/{bp_low_dia} mmHg |
| **Nh·ªãp tim TB** | {hr_avg:.0f} bpm |

### 2.2 ƒê·ªô ·ªîn ƒê·ªãnh HA (ARV)

| Ch·ªâ s·ªë | Gi√° tr·ªã | Ph√¢n lo·∫°i | Ng∆∞·ª°ng |
|:---|:---|:---|:---|
| **ARV t√¢m thu** | {arv:.1f} | **{arv_class}** | {arv_note} |

### 2.3 Nh·ªãp Sinh H·ªçc HA (ME diff)

| Ch·ªâ s·ªë | Gi√° tr·ªã | Ph√¢n lo·∫°i | Ng∆∞·ª°ng |
|:---|:---|:---|:---|
| **ME diff** | {f"{mediff:+.0f}" if mediff else "N/A"} mmHg | **{mediff_class}** | {mediff_note} |

### 2.4 Ph√°t Hi·ªán B·∫•t Th∆∞·ªùng

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|:---|:---|
| **S·ªë l·∫ßn v∆∞·ª£t ng∆∞·ª°ng** | {abnormal['count_out']}/{abnormal['total']} l·∫ßn ({100-kiem_soat:.1f}%) |
| **Th·ªùi ƒëi·ªÉm th∆∞·ªùng x·∫£y ra** | Bu·ªïi {abnormal['peak_time']} |

---

## 3. Ph√¢n T√≠ch Nh·ªãp Tim

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|:---|:---|
| **Nh·ªãp tim Trung b√¨nh** | {hr_analysis['avg']:.0f} bpm |
| **Nh·ªãp tim Cao nh·∫•t** | {hr_analysis['max']} bpm |
| **Nh·ªãp tim Th·∫•p nh·∫•t** | {hr_analysis['min']} bpm |

{"‚úÖ Nh·ªãp tim ·ªïn ƒë·ªãnh" if hr_analysis['too_fast'] == 0 and hr_analysis['too_slow'] == 0 else f"‚ö†Ô∏è Ph√°t hi·ªán b·∫•t th∆∞·ªùng: Nhanh: {hr_analysis['too_fast']}, Ch·∫≠m: {hr_analysis['too_slow']}"}

---

## 4. L·ªùi Khuy√™n Th√°ng T·ªõi

"""
    if kiem_soat > 70:
        report += """üéâ **Xu·∫•t s·∫Øc!** Ti·∫øp t·ª•c duy tr√¨."""
    elif kiem_soat >= 50:
        report += """üëç **Kh√° t·ªët!** C·ªë g·∫Øng n√¢ng t·ª∑ l·ªá ki·ªÉm so√°t >70%."""
    else:
        report += """‚ö†Ô∏è **C·∫ßn c·∫£i thi·ªán!** Tham kh·∫£o √Ω ki·∫øn b√°c sƒ©."""

    report += f"""

---

> *B√°o c√°o ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông theo SRS BR-005*  
> *L∆∞u √Ω: B√°o c√°o n√†y kh√¥ng thay th·∫ø t∆∞ v·∫•n y khoa.*
"""
    
    return report

def process_user(user_dir):
    print(f"\n{'='*60}")
    print(f"Processing: {os.path.basename(user_dir)}")
    print(f"{'='*60}")
    
    config = load_user_config(user_dir)
    print(f"  Lo·∫°i: {config['user_type']}")
    print(f"  Ng∆∞·ª°ng: SYS {config['sys_lower']}-{config['sys_upper']}, DIA {config['dia_lower']}-{config['dia_upper']}")
    
    bp_file = os.path.join(user_dir, 'user_blood_pressure.csv')
    if not os.path.exists(bp_file):
        print(f"  ‚ùå Kh√¥ng t√¨m th·∫•y user_blood_pressure.csv")
        return
    
    # ƒê·ªçc d·ªØ li·ªáu
    with open(bp_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        data = []
        for row in reader:
            if row.get('measurement_time'):
                data.append({
                    'dt': parse_datetime(row['measurement_time']),
                    'sys': int(row['systolic']),
                    'dia': int(row['diastolic']),
                    'hr': int(row['heart_rate'])
                })
    
    events = load_events(user_dir)
    print(f"  ƒê·ªçc ƒë∆∞·ª£c {len(data)} l·∫ßn ƒëo, {len(events)} s·ª± ki·ªán")
    
    # T·∫°o th∆∞ m·ª•c week/month
    week_dir = os.path.join(user_dir, 'week')
    month_dir = os.path.join(user_dir, 'month')
    os.makedirs(week_dir, exist_ok=True)
    os.makedirs(month_dir, exist_ok=True)
    
    # Group theo tu·∫ßn
    weeks = defaultdict(list)
    for r in data:
        week_start = get_week_monday(r['dt'])
        weeks[week_start].append(r)
    
    # Group theo th√°ng
    months = defaultdict(list)
    for r in data:
        month_key = (r['dt'].year, r['dt'].month)
        months[month_key].append(r)
    
    # T·∫°o reports tu·∫ßn
    print("  T·∫°o b√°o c√°o tu·∫ßn...")
    sorted_weeks = sorted(weeks.keys())
    prev_sys_avg = None
    prev_week_data = None
    
    for i, week_start in enumerate(sorted_weeks):
        week_data = weeks[week_start]
        week_num = i + 1
        week_end = week_start + timedelta(days=6)
        
        report, sys_avg = generate_week_report(
            week_start, week_data, week_num, events, config,
            prev_week_data, prev_sys_avg
        )
        
        filename = os.path.join(week_dir, f"{week_start.strftime('%Y-%m-%d')}_{week_end.strftime('%Y-%m-%d')}.md")
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        prev_sys_avg = sys_avg
        prev_week_data = week_data
    
    print(f"    ‚úÖ {len(weeks)} b√°o c√°o tu·∫ßn")
    
    # T·∫°o reports th√°ng
    print("  T·∫°o b√°o c√°o th√°ng...")
    sorted_months = sorted(months.keys())
    for i, month_key in enumerate(sorted_months):
        month_data = months[month_key]
        prev_data = months[sorted_months[i-1]] if i > 0 else None
        report = generate_month_report(month_key, month_data, config, prev_data)
        
        year, month = month_key
        filename = os.path.join(month_dir, f"month_{year}-{month:02d}.md")
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)
    
    print(f"    ‚úÖ {len(months)} b√°o c√°o th√°ng")

def main():
    base_dir = "/Users/teamai/Downloads/antigravity/koliaa/Huongttt/feature/bao_cao/csv/Data_import/insert_dev"
    
    users = ['user_tha', 'user_ko_on_dinh', 'user_ha_thap', 'user_bp_load']
    
    for user in users:
        user_dir = os.path.join(base_dir, user)
        if os.path.exists(user_dir):
            process_user(user_dir)
        else:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y: {user_dir}")
    
    print("\nüéâ HO√ÄN TH√ÄNH T·∫§T C·∫¢!")

if __name__ == '__main__':
    main()
